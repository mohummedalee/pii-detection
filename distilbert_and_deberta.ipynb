{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb2eeb2-600e-4aa9-825e-55194ecfccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f87b37-a5f3-448a-b135-4c58ec6c5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadali/Desktop/kaggle/pii-detection-removal-from-educational-data/.kaggle/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%aimport preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c802238-e63d-415c-bc40-7e958fd40320",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = 'train.json'\n",
    "file_test = 'test.json'\n",
    "\n",
    "MAXLEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6184c9-a52c-457a-93d7-353b567c4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(file_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf5e46-1c7d-4c02-bc83-1e5223a1a078",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "**Step 1**: Convert `labels` column into ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11365550-fe32-4965-aa84-d6110ece3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O',\n",
    "  'B-NAME_STUDENT',\n",
    "  'I-NAME_STUDENT',\n",
    "  'B-EMAIL',\n",
    "  'I-EMAIL',\n",
    "  'B-USERNAME',\n",
    "  'I-USERNAME',\n",
    "  'B-ID_NUM',\n",
    "  'I-ID_NUM',\n",
    "  'B-PHONE_NUM',\n",
    "  'I-PHONE_NUM',\n",
    "  'B-URL_PERSONAL',\n",
    "  'I-URL_PERSONAL',\n",
    "  'B-STREET_ADDRESS',\n",
    "  'I-STREET_ADDRESS'\n",
    "]\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11674ee-ebd8-4f05-9dd5-3b3841dbd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mapped_labels(labels):\n",
    "    mapped_labels = pd.DataFrame({\n",
    "        'mapped_labels': labels\n",
    "    })['mapped_labels'].map(label2id).tolist()\n",
    "\n",
    "    return mapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4528b8fe-db06-4a1a-8b98-aa12ffc026e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical column -- friendlier for classifiers\n",
    "df['labels_cat'] = df['labels'].apply(create_mapped_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa27dde6-22cb-436f-897c-a863d96788d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample because too many non-PII examples\n",
    "filter = df['labels'].apply(lambda arr: any([l != 'O' for l in arr]))\n",
    "downsampled_df = df[filter]\n",
    "\n",
    "train, valid = train_test_split(downsampled_df, test_size=0.1, shuffle=True, random_state=22124)\n",
    "\n",
    "def create_dataset(df):\n",
    "    ds = Dataset.from_dict({\n",
    "        'document': [d for d in df['document']],\n",
    "        'full_text': [ft for ft in df['full_text']],\n",
    "        'tokens': [t for t in df['tokens']],\n",
    "        'trailing_whitespace': [tw for tw in df['trailing_whitespace']],\n",
    "        'labels': [l for l in df['labels']],\n",
    "        'labels_cat': [ml for ml in df['labels_cat']]\n",
    "    })\n",
    "    return ds\n",
    "\n",
    "train_ds = create_dataset(train)\n",
    "valid_ds = create_dataset(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a383b5-8915-4683-912d-b587b4ffd697",
   "metadata": {},
   "source": [
    "#### Some preprocessing helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "993de1da-c08f-4fea-9005-65030aecb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        # pdb.set_trace()\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    \"\"\"\n",
    "    After running tokenizer, word ids can get misaligned\n",
    "    need to re-align BIO labels, i.e. make sure split-up words\n",
    "    get tagged as I-, [CLS] and [SEP] etc. are given sentinel values\n",
    "    \"\"\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], padding=True, truncation=True, is_split_into_words=True, max_length=MAXLEN\n",
    "    )\n",
    "    # pdb.set_trace()\n",
    "    all_labels = examples[\"labels_cat\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)                \n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "    \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d484b8-ee4b-45e5-9670-90a448091ebf",
   "metadata": {},
   "source": [
    "### Finetune LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "192b6685-e8ca-481f-bce2-afea3365f352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|█| 52.0/52.0 [00:00<00:00, 144kB/s]\n",
      "config.json: 100%|████████████| 578/578 [00:00<00:00, 1.11MB/s]\n",
      "spm.model: 100%|██████████| 2.46M/2.46M [00:00<00:00, 13.0MB/s]\n",
      "/Users/muhammadali/Desktop/kaggle/pii-detection-removal-from-educational-data/.kaggle/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:515: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# MODEL = 'microsoft/deberta-v3-small'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0e8005c-b8bb-405b-a2ba-0199cf942c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'distilbert/distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17ca897a-02d6-428f-9f4c-96f80bfdaa6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████| 850/850 [00:00<00:00, 888.21 examples/s]\n",
      "Map: 100%|█████████████| 95/95 [00:00<00:00, 872.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = train_ds.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_valid = valid_ds.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "674fb4e1-cf00-4875-a421-c0fa2424fd2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, pad_to_multiple_of=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f9744-82d2-4054-8dbe-3b411bfc9ca1",
   "metadata": {},
   "source": [
    "##### Define eval metrics before starting finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e85756-7621-49dc-9574-8b13e735d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import recall_score, precision_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(p, label_list):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    f1_score = (1 + 5*5) * recall * precision / (5*5*precision + recall)\n",
    "    \n",
    "    results = {\n",
    "        'recall': recall,\n",
    "        'precision': precision,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438326cd-b0aa-474c-beef-39c4af1082e8",
   "metadata": {},
   "source": [
    "**Finally**, the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d796ef-3770-4e2d-9f12-48dc0e932c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6ec84df-c839-44ca-b4bf-c20b523f4a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebcbe709-847d-416f-9d6a-b0676643ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='output',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2ae5f696-d842-4fb4-889d-b8e83d7ddd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2550' max='2550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2550/2550 04:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.805755</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.800220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.009806</td>\n",
       "      <td>0.741007</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.740802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.009322</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>0.834763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2550, training_loss=0.018512891536834192, metrics={'train_runtime': 284.2429, 'train_samples_per_second': 8.971, 'train_steps_per_second': 8.971, 'total_flos': 333243717580800.0, 'train_loss': 0.018512891536834192, 'epoch': 3.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_valid,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=partial(compute_metrics, label_list=label_list)\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a394cee5-e55b-42aa-b775-848de4abd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('distilbert-finetuned-downsampled-512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc13aa8a-b4b2-4283-b9db-26bd84476268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb                       preprocess.py\n",
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m                          sample_submission.csv\n",
      "\u001b[1m\u001b[36mdistilbert-finetuned-downsampled-512\u001b[m\u001b[m scratch.ipynb\n",
      "distilbert_and_deberta.ipynb         test.json\n",
      "\u001b[1m\u001b[36moutput\u001b[m\u001b[m                               train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
