{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for PII Data Detection\n",
    "\n",
    "Many thanks to [@thedrcat](https://www.kaggle.com/thedrcat) for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6807"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "train = json.load(open(\"../data/train.json\"))\n",
    "df = pd.DataFrame(train)\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Split\n",
    "\n",
    "Let's start by checking out the distribution of labels across all training essays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL: 24\n",
      "ID_NUM: 33\n",
      "NAME_STUDENT: 891\n",
      "PHONE_NUM: 4\n",
      "STREET_ADDRESS: 2\n",
      "URL_PERSONAL: 72\n",
      "USERNAME: 5\n",
      "OTHER: 5862\n"
     ]
    }
   ],
   "source": [
    "def encode_labels(df):\n",
    "    # unique_labels within each row\n",
    "    df[\"unique_labels\"] = df[\"labels\"].apply(lambda x: list(set(\n",
    "        [l.split('-')[1] for l in x if l != 'O']\n",
    "         )))\n",
    "    # add 1-hot encoding\n",
    "    from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    # fit on whole dataframe, see all labels over all datapoints (train+val)\n",
    "    one_hot_encoded = mlb.fit_transform(df['unique_labels'])\n",
    "    one_hot_df = pd.DataFrame(one_hot_encoded, columns=mlb.classes_)\n",
    "    df = pd.concat([df, one_hot_df], axis=1)\n",
    "    \n",
    "    # add 'OTHER' column indicating no PII\n",
    "    df['OTHER'] = df['unique_labels'].apply(lambda x: 1 if len(x) == 0 else 0)\n",
    "    \n",
    "    return df, list(mlb.classes_) + ['OTHER']\n",
    "\n",
    "df, label_classes = encode_labels(df)\n",
    "\n",
    "for col in label_classes:\n",
    "    print(f'{col}: {df[col].sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want all the very rare classes to be in my validation split. This is going to be an opinionated split, but I'd like to pick the following numbers into my validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID EMAIL: 13\n",
      "TRAIN EMAIL: 11\n",
      "VALID ID_NUM: 13\n",
      "TRAIN ID_NUM: 20\n",
      "VALID NAME_STUDENT: 124\n",
      "TRAIN NAME_STUDENT: 767\n",
      "VALID PHONE_NUM: 4\n",
      "TRAIN PHONE_NUM: 0\n",
      "VALID STREET_ADDRESS: 2\n",
      "TRAIN STREET_ADDRESS: 0\n",
      "VALID URL_PERSONAL: 26\n",
      "TRAIN URL_PERSONAL: 46\n",
      "VALID USERNAME: 5\n",
      "TRAIN USERNAME: 0\n",
      "VALID OTHER: 1000\n",
      "TRAIN OTHER: 4862\n",
      "# TRAIN: 5661\n",
      "# VALID: 1146\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "# Create a 'valid' column and set it to False\n",
    "df['valid'] = False\n",
    "\n",
    "# Define the validation numbers\n",
    "val_nums = {\n",
    "    'EMAIL': 12,\n",
    "    'ID_NUM': 12,\n",
    "    'NAME_STUDENT': 100,\n",
    "    'PHONE_NUM': 4,\n",
    "    'STREET_ADDRESS': 2,\n",
    "    'URL_PERSONAL': 20,\n",
    "    'USERNAME': 5,\n",
    "    'OTHER': 1000, \n",
    "}\n",
    "\n",
    "# For each class in val_nums, randomly select the specified number of examples and set 'valid' to True\n",
    "for label, num in val_nums.items():\n",
    "    valid_indices = df[df[label] == 1].sample(n=num, random_state=42).index\n",
    "    df.loc[valid_indices, 'valid'] = True\n",
    "\n",
    "\n",
    "# Let's double check the classes per split:\n",
    "for col in label_classes:\n",
    "    print(f'VALID {col}: {df[df.valid == True][col].sum()}')\n",
    "    print(f'TRAIN {col}: {df[df.valid == False][col].sum()}')\n",
    "\n",
    "# train vs. valid\n",
    "print(f'# TRAIN: {(df.valid == False).sum()}')\n",
    "print(f'# VALID: {(df.valid == True).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "Let's prepare the visualization code based on [this great notebook](https://www.kaggle.com/code/sinchir0/visualization-code-using-displacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/sinchir0/visualization-code-using-displacy\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "options = {\n",
    "    \"colors\": {\n",
    "        \"B-NAME_STUDENT\": \"aqua\",\n",
    "        \"I-NAME_STUDENT\": \"skyblue\",\n",
    "        \"B-EMAIL\": \"limegreen\",\n",
    "        \"I-EMAIL\": \"lime\",\n",
    "        \"B-USERNAME\": \"hotpink\",\n",
    "        \"I-USERNAME\": \"lightpink\",\n",
    "        \"B-ID_NUM\": \"purple\",\n",
    "        \"I-ID_NUM\": \"rebeccapurple\",\n",
    "        \"B-PHONE_NUM\": \"red\",\n",
    "        \"I-PHONE_NUM\": \"salmon\",\n",
    "        \"B-URL_PERSONAL\": \"silver\",\n",
    "        \"I-URL_PERSONAL\": \"lightgray\",\n",
    "        \"B-STREET_ADDRESS\": \"brown\",\n",
    "        \"I-STREET_ADDRESS\": \"chocolate\",\n",
    "    }\n",
    "}\n",
    "\n",
    "def visualize(row):\n",
    "    doc = nlp(row.full_text)\n",
    "    doc.ents = [\n",
    "        Span(doc, idx, idx + 1, label=label)\n",
    "        for idx, label in enumerate(row.labels)\n",
    "        if label != \"O\"\n",
    "    ]\n",
    "    html = displacy.render(doc, style=\"ent\", jupyter=False, options=options)\n",
    "    return html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z5/k12y6ny94zs4lswtcxyb_0sw0000gn/T/ipykernel_91370/2911266901.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Design Thinking for innovation reflexion-Avril 2021-\n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nathalie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-NAME_STUDENT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: skyblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sylla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-NAME_STUDENT</span>\n",
       "</mark>\n",
       "<br><br>Challenge &amp; selection<br><br>The tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.<br><br>What exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1<br><br>This tool has many advantages:<br><br>•  It is accessible to all and does not require significant material investment and can be done  quickly<br><br>•  It is scalable<br><br>•  It allows categorization and linking of information<br><br>•  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas<br><br>•  It is suitable for all people and is easy to learn<br><br>•  It is fun and encourages exchanges<br><br>•  It makes visible the dimension of projects, opportunities, interconnections<br><br>•  It synthesizes<br><br>•  It makes the project understandable<br><br>•  It allows you to explore ideas<br><br>The creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.<br><br>This tool enables creativity and logic to be mobilized, it is a map of the thoughts.<br><br>Creativity is enhanced because participants feel comfortable with the method.<br><br>Application &amp; Insight<br><br>I start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.<br><br>Through a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.<br><br>The use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.<br><br>Design Thinking for innovation reflexion-Avril 2021-\n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nathalie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-NAME_STUDENT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: skyblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sylla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-NAME_STUDENT</span>\n",
       "</mark>\n",
       "<br><br>After modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.<br><br>I now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.<br><br>Approach<br><br>What I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.<br><br>Design Thinking for innovation reflexion-Avril 2021-\n",
       "<mark class=\"entity\" style=\"background: aqua; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nathalie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">B-NAME_STUDENT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: skyblue; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sylla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">I-NAME_STUDENT</span>\n",
       "</mark>\n",
       "<br><br>Annex 1: Mind Map Shared facilities project<br><br></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "html = visualize(df.loc[0])\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncation with stride\n",
    "\n",
    "There are two ways to do striding here - the best is probably to use tokenizers striding method. I opted for the easy way here and applied striding using spacy tokens. This means we're still facing variable sequence length after tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_indices(doc_tokens):\n",
    "    token_indices = list(range(len(doc_tokens)))\n",
    "    return token_indices\n",
    "\n",
    "df['token_indices'] = df['tokens'].apply(add_token_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_text(tokens, trailing_whitespace):\n",
    "    text = ''\n",
    "    for token, ws in zip(tokens, trailing_whitespace):\n",
    "        ws = \" \" if ws == True else \"\"\n",
    "        text += token + ws\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_rows(df, max_length, doc_stride):\n",
    "    \"\"\"\n",
    "    breaks text into doc_stride\n",
    "    \"\"\"\n",
    "    new_df = []\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = row['tokens']\n",
    "        if len(tokens) > max_length:\n",
    "            # need to break text into `max_length` segments at `doc_stride` tokens apart\n",
    "            start = 0\n",
    "            while start < len(tokens):\n",
    "                remaining_tokens = len(tokens) - start\n",
    "                if remaining_tokens < max_length and start != 0:\n",
    "                    # tokens remain and I am not at the beginning of text\n",
    "                    # Adjust start for the last window to ensure it has max_length tokens\n",
    "                    start = max(0, len(tokens) - max_length)\n",
    "                end = min(start + max_length, len(tokens))\n",
    "                new_row = {}\n",
    "                new_row['document'] = row['document']\n",
    "                new_row['valid'] = row['valid']\n",
    "                new_row['tokens'] = tokens[start:end]\n",
    "                new_row['trailing_whitespace'] = row['trailing_whitespace'][start:end]\n",
    "                new_row['labels'] = row['labels'][start:end]\n",
    "                new_row['token_indices'] = list(range(start, end))\n",
    "                new_row['full_text'] = rebuild_text(new_row['tokens'], new_row['trailing_whitespace'])\n",
    "                new_df.append(new_row)\n",
    "                if remaining_tokens >= max_length:\n",
    "                    # make a stride, not necessarily all the way to max_length\n",
    "                    start += doc_stride\n",
    "                else:\n",
    "                    # Break the loop if we've adjusted for the last window\n",
    "                    break\n",
    "        else:\n",
    "            # text was less than max_length, keep as is\n",
    "            new_row = {\n",
    "                'document': row['document'], \n",
    "                'valid': row['valid'],\n",
    "                'tokens': row['tokens'], \n",
    "                'trailing_whitespace': row['trailing_whitespace'], \n",
    "                'labels': row['labels'], \n",
    "                'token_indices': row['token_indices'], \n",
    "                'full_text': row['full_text']\n",
    "            }\n",
    "            new_df.append(new_row)\n",
    "    return pd.DataFrame(new_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6807 11468\n"
     ]
    }
   ],
   "source": [
    "max_length = 750\n",
    "doc_stride = 250\n",
    "stride_df = split_rows(df, max_length, doc_stride)\n",
    "\n",
    "print(len(df), len(stride_df))\n",
    "stride_df, label_classes = encode_labels(stride_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EMAIL',\n",
       " 'ID_NUM',\n",
       " 'NAME_STUDENT',\n",
       " 'PHONE_NUM',\n",
       " 'STREET_ADDRESS',\n",
       " 'URL_PERSONAL',\n",
       " 'USERNAME',\n",
       " 'OTHER']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of how stride works:\n",
    "\n",
    "See below. This is equivalent to splitting text in `text[start:max_length:doc_stride]` chunks, where `start += doc_stride` in each iteration. This provides richer text than just truncating at max_length and combining remaining tokens into a leftover piece of text. With this method, the leftover text has additional context that of at least `doc_stride` length. Very interesting approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENGLISH    Introduction  I have been working in a transnational company, with a track record of more than 20 years in the market.  My country\\'s subsidiary has almost 5,000 employees with three business units: Operations, Customer  Service and Finance Shared Services. I work for the Human Resources department as a Talent  Acquisition Partner, where the monthly hiring volume is more than 100 people every two weeks.    Challenge   In the Finance Shared Services Unit, high volume of staff is hired, one of the positions that is most  contracted from Collector\\'s. This role is in high demand in the market, it is already key for all companies  that sell services or products and are responsible for collecting the money that customers owe to the  company.    During the last year, 18 of these positions were opened, of which 8 new hires resigned before the end of  the first year, raising the level of attrition, increasing the Budget for training of new hires and generating a  high level of stress and pressure on the part of the Hiring Manager on the recruitment team to replace the  places to be as possible.    Selection  I selected the Mind Mapping tool to do this exercise. As we know it is a tool that sees the possible  connections between various thoughts and using visual tools.    A set of activities is carried out to develop the client\\'s needs for each moment, and the points of contact  between him and the company. I considered this ideal tool in this case, since it allows meticulous  monitoring of all the elements and tools that interact with the client (hiring manager) during the  recruitment, selection and retention of personnel, identifying the touch points to be analyzed and  improved.    The tool was defined in this way by Tony Buzan, and I also relied on his book \"El libro de los mapas  mentales” April 2017, to develop this homework.      Application   In applying the tool, I divided the mind map into the actors and processes involved as follows:    • The manager: validates the need to hire new staff focused on the forecast vs the Budget assigned for  hiring, based on these numbers, requests the talent Acquisition team to hire the vacant positions.    • Talent Acquisition: publish vacancies, filter the best candidates that have applied and carry out the entire  recruitment and selection process.    • During the selection process: each candidate is validated through specific recruitment tests and  interviews for topics such as: experience, motivation to accept the position, salary claim and expectations  for future growth, among other soft and technical skills.    • Benefits offered to the candidate: during this process, the candidate is made to see how solid the  company is, that we can give it job stability, competitive salary (50th percentile), excellent benefits  (medical and life insurance, annual bonus, doctor on site , free transportation or parking space, subsidized\\n\\nfood and growth possibilities). The person hired goes through an onboarding and training process already  established in a solid department of more than 60 people.    • Points of contact in the process:   1. Recruitment / Hiring Manager   2. Hiring Manager / Traing team   3. Hiring Manager / Team    • Points of friction and most frequent problems in the process:   1. More than 50% of the applicants do not meet the profile required by the position   2. 26% of the pre-selected candidates do not pass the selection processes   3. 5% of candidates do not accept the offer   4. 44.4% of the people hired resign before reaching the company for one year   5. Hiring and Training each new employee costs the company $ 5000    Insight  An in-depth interview with the hiring manager was applied. A statistical analysis will be performed to  obtain more data. Data was requested from the training and finance department to validate the costs of  hiring and training each new employee.    It is necessary to maintain a balance between desertion, training budget and the professional career of the  employees, to achieve this it is proposed to create an internship program (recent graduates with little work  experience) where employees can be trained by the company and thus offer you a professional career  internally.    Approach   During a second exercise, the challenge will be to do this same employee-focused mapping as my  customer and understand from their perspective as a collector what could change/be done better by the  company,  starting from their experience as a candidate during the hiring process, following onborarding,  training, leadership style and learning and development opportunities.\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH    Introduction  I have been working in a transnational company, with a track record of more than 20 years in the market.  My country's subsidiary has almost 5,000 employees with three business units: Operations, Customer  Service and Finance Shared Services. I work for the Human Resources department as a Talent  Acquisition Partner, where the monthly hiring volume is more than 100 people every two weeks.    Challenge   In the Finance Shared Services Unit, high volume of staff is hired, one of the positions that is most  contracted from Collector's. This role is in high demand in the market, it is already key for all companies  that sell services or products and are responsible for collecting the money that customers owe to the  company.    During the last year, 18 of these positions were opened, of which 8 new hires resigned before the end of  the first year, raising the level of attrition, increasing the Budget for training of new hires and generating a  high level of stress and pressure on the part of the Hiring Manager on the recruitment team to replace the  places to be as possible.    Selection  I selected the Mind Mapping tool to do this exercise. As we know it is a tool that sees the possible  connections between various thoughts and using visual tools.    A set of activities is carried out to develop the client's needs for each moment, and the points of contact  between him and the company. I considered this ideal tool in this case, since it allows meticulous  monitoring of all the elements and tools that interact with the client (hiring manager) during the  recruitment, selection and retention of personnel, identifying the touch points to be analyzed and  improved.    The tool was defined in this way by Tony Buzan, and I also relied on his book \"El libro de los mapas  mentales” April 2017, to develop this homework.      Application   In applying the tool, I divided the mind map into the actors and processes involved as follows:    • The manager: validates the need to hire new staff focused on the forecast vs the Budget assigned for  hiring, based on these numbers, requests the talent Acquisition team to hire the vacant positions.    • Talent Acquisition: publish vacancies, filter the best candidates that have applied and carry out the entire  recruitment and selection process.    • During the selection process: each candidate is validated through specific recruitment tests and  interviews for topics such as: experience, motivation to accept the position, salary claim and expectations  for future growth, among other soft and technical skills.    • Benefits offered to the candidate: during this process, the candidate is made to see how solid the  company is, that we can give it job stability, competitive salary (50th percentile), excellent benefits  (medical and life insurance, annual bonus, doctor on site , free transportation or parking space, subsidized\n",
      "\n",
      "food and growth possibilities). The person hired goes through an onboarding and training process already  established in a solid department of more than 60 people.    • Points of contact in the process:   1. Recruitment / Hiring Manager   2. Hiring Manager / Traing team   3. Hiring Manager / Team    • Points of friction and most frequent problems in the process:   1. More than 50% of the applicants do not meet the profile required by the position   2. 26% of the pre-selected candidates do not pass the selection processes   3. 5% of candidates do not accept the offer   4. 44.4% of the people hired resign before reaching the company for one year   5. Hiring and Training each new employee costs the company $ 5000    Insight  An in-depth interview with the hiring manager was applied. A statistical analysis will be performed to  obtain more data.  \n",
      "\n",
      "-----\n",
      " these positions were opened, of which 8 new hires resigned before the end of  the first year, raising the level of attrition, increasing the Budget for training of new hires and generating a  high level of stress and pressure on the part of the Hiring Manager on the recruitment team to replace the  places to be as possible.    Selection  I selected the Mind Mapping tool to do this exercise. As we know it is a tool that sees the possible  connections between various thoughts and using visual tools.    A set of activities is carried out to develop the client's needs for each moment, and the points of contact  between him and the company. I considered this ideal tool in this case, since it allows meticulous  monitoring of all the elements and tools that interact with the client (hiring manager) during the  recruitment, selection and retention of personnel, identifying the touch points to be analyzed and  improved.    The tool was defined in this way by Tony Buzan, and I also relied on his book \"El libro de los mapas  mentales” April 2017, to develop this homework.      Application   In applying the tool, I divided the mind map into the actors and processes involved as follows:    • The manager: validates the need to hire new staff focused on the forecast vs the Budget assigned for  hiring, based on these numbers, requests the talent Acquisition team to hire the vacant positions.    • Talent Acquisition: publish vacancies, filter the best candidates that have applied and carry out the entire  recruitment and selection process.    • During the selection process: each candidate is validated through specific recruitment tests and  interviews for topics such as: experience, motivation to accept the position, salary claim and expectations  for future growth, among other soft and technical skills.    • Benefits offered to the candidate: during this process, the candidate is made to see how solid the  company is, that we can give it job stability, competitive salary (50th percentile), excellent benefits  (medical and life insurance, annual bonus, doctor on site , free transportation or parking space, subsidized\n",
      "\n",
      "food and growth possibilities). The person hired goes through an onboarding and training process already  established in a solid department of more than 60 people.    • Points of contact in the process:   1. Recruitment / Hiring Manager   2. Hiring Manager / Traing team   3. Hiring Manager / Team    • Points of friction and most frequent problems in the process:   1. More than 50% of the applicants do not meet the profile required by the position   2. 26% of the pre-selected candidates do not pass the selection processes   3. 5% of candidates do not accept the offer   4. 44.4% of the people hired resign before reaching the company for one year   5. Hiring and Training each new employee costs the company $ 5000    Insight  An in-depth interview with the hiring manager was applied. A statistical analysis will be performed to  obtain more data. Data was requested from the training and finance department to validate the costs of  hiring and training each new employee.    It is necessary to maintain a balance between desertion, training budget and the professional career of the  employees, to achieve this it is proposed to create an internship program (recent graduates with little work  experience) where employees can be trained by the company and thus offer you a professional career  internally.    Approach   During a second exercise, the challenge will be to do this same employee-focused mapping as my  customer and understand from their perspective as a collector what could change/be done better by the  company,  starting from their experience as a candidate during the hiring process, following onborarding,  training, leadership style and learning and development opportunities.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    stride_df.iloc[0]['full_text'], '\\n\\n-----\\n',\n",
    "    stride_df.iloc[1]['full_text']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving to W&B\n",
    "\n",
    "It's best practice to version datasets properly and visualize them in W&B. Let's do this!\n",
    "\n",
    "To run below code, please add your `WANDB_API_KEY` secret to Kaggle notebook secrets. You can get it [here](https://wandb.ai/authorize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/muhammadali/Desktop/kaggle/pii-detection-removal-from-educational-data/instrumented'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up weights and biases API key\n",
    "try:\n",
    "    # if running in Kaggle Notebooks\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    wandb_api_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
    "except:\n",
    "    # if running locally\n",
    "    wandb_api_key = open(\".wanb.key\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/muhammadali/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmuhammadali\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/muhammadali/Desktop/kaggle/pii-detection-removal-from-educational-data/instrumented/wandb/run-20240330_165939-tx6ysvqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo/workspace' target=\"_blank\">lively-firefly-1</a></strong> to <a href='https://wandb.ai/muhammadali/kaggle-pii-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/muhammadali/kaggle-pii-detection' target=\"_blank\">https://wandb.ai/muhammadali/kaggle-pii-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo/workspace' target=\"_blank\">https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x35f8f8b00>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=wandb_api_key)\n",
    "wandb.init(project='kaggle-pii-detection', job_type='preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add our hyperparameters to the config \n",
    "wandb.config.update({\n",
    "    'max_length': max_length,\n",
    "    'doc_stride': doc_stride,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Artifact processed_data>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first log data as artifacts\n",
    "df.to_parquet('raw_data.parquet', index=False)\n",
    "stride_df.to_parquet('stride_data.parquet', index=False)\n",
    "\n",
    "raw_data = wandb.Artifact(name=\"raw_data\", type=\"dataset\")\n",
    "raw_data.add_file('raw_data.parquet')\n",
    "wandb.log_artifact(raw_data)\n",
    "\n",
    "processed_data = wandb.Artifact(name=\"processed_data\", type=\"dataset\")\n",
    "processed_data.add_file('stride_data.parquet')\n",
    "wandb.log_artifact(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadali/miniconda3/envs/kaggle/lib/python3.12/site-packages/spacy/displacy/__init__.py:213: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
      "  warnings.warn(Warnings.W006)\n"
     ]
    }
   ],
   "source": [
    "# We will generate html viz for every train essay, wrap it up in `wandb.Html` and create a W&B table to inspect it\n",
    "wandb_htmls = [wandb.Html(visualize(row)) for _, row in df.iterrows()]\n",
    "df['visualization'] = wandb_htmls\n",
    "table = wandb.Table(dataframe=df)\n",
    "wandb.log({'original_dataset': table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lively-firefly-1</strong> at: <a href='https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo/workspace' target=\"_blank\">https://wandb.ai/muhammadali/kaggle-pii-detection/runs/tx6ysvqo/workspace</a><br/>Synced 6 W&B file(s), 1 media file(s), 6812 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240330_165939-tx6ysvqo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
